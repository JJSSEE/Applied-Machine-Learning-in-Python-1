{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "\n",
    "\n",
    "** Problem 1**\n",
    "\n",
    "Explore the Wine data set, which contains 13 attributes (features) and three classes (types of wine). Use the _iris_ _flower_ example presented in the class to:\n",
    "\n",
    "1) Create a dataframe from the raw data. Understand dimensions, types of variables, feature names.\n",
    "\n",
    "2) Learn how to get a single column from the dataframe, computes mean and std along each columns.\n",
    "\n",
    "3) Plot the distributions of features (histograms), understand which features have more variability (potentially might be good discriminative features)\n",
    "\n",
    "4) Create 'X' and 'y' dataframes, which correspond to features and class labels respectively.\n",
    "\n",
    "5) Split the entire data set into _training_ and _test_ sets\n",
    "\n",
    "6) Learn a classifier on the training set and check its performance in the test set\n",
    "\n",
    "7) Plot the confusion matrix and compute the accuracy score: a single number which summarises the performance of the classifier\n",
    "\n",
    "(continue with the code presented below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datafrane object\n",
    "import pandas as pd\n",
    "\n",
    "# general library for numerical tensors\n",
    "import numpy as np\n",
    "\n",
    "# data visualisation\n",
    "import seaborn as  sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import 'datasets' library from sci0kit learn ML package\n",
    "from sklearn import datasets\n",
    "\n",
    "# import a simple linear classification algorithm: logistic regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# import a metric for the assessment of accuracy of classification\n",
    "from sklearn import metrics\n",
    "\n",
    "# obtain the wine data set\n",
    "wine_data = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**\n",
    "\n",
    "Explore the Titanic data set (included in the folder 'data'). Repeat the exploration steps mentioned in *Practice 1*.\n",
    "\n",
    "The outcome / class you will be predicting is the survival probability (rounded to binary values 1/0) and labeled by **'survived'** column. \n",
    "\n",
    "1) Understand how the data were loaded into pandas dataframe and split into features and outcomes (see below).\n",
    "\n",
    "2) Train a classifier using all features and also a random subset ().\n",
    "\n",
    "3) Explore various feature subset which produce higher classification accuracy. For example, features ['class', 'age', 'sex']\n",
    "\n",
    "** amazing tutorial using this data set:** https://www.kaggle.com/startupsci/titanic-data-science-solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_titanic_data = pd.read_excel('data/titanic.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
      "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "print df_titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I split the entire data set into 'features' and the 'outcomes'\n",
    "# X - features (13 attributes) and y - outcome binary variable: survived 1, did not survive = 0\n",
    "X, y = df_titanic_data.loc[:,df_titanic_data.columns !='survived'], df_titanic_data.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
